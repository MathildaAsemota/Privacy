{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbm39dGaxONKYb9m9ln3cZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathildaAsemota/Privacy/blob/main/Mnist3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split  # For splitting the data\n",
        "from torch.utils.data import SubsetRandomSampler, DataLoader  # For sampling and DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Device Config\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "vuUnDQNHMehC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BFmnSKfATGGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_new_classes = 2   # 0 and 1\n",
        "n_epochs = 40\n",
        "new_batch_size = 64\n",
        "learning_rate = 0.0001\n",
        "n_features = 28 * 28\n",
        "n_hidden = 100\n"
      ],
      "metadata": {
        "id": "2xIzcKVCUTJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "train_data = torchvision.datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = torchvision.datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "5GYFWsa1UTMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92bcdb4b-6daa-4f6d-af39-70bd7e507de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 39.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.26MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.07MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class YourSampler(torch.utils.data.sampler.Sampler):\n",
        "    def __init__(self, mask, data_source):\n",
        "        self.mask = mask\n",
        "        self.data_source = data_source\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter([i.item() for i in torch.nonzero(mask)])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_source)\n",
        "\n",
        "mnist = torchvision.datasets.MNIST(root=\"data\", download=True, transform=transforms.ToTensor())\n",
        "mask = [1 if mnist[i][1] == 0 or mnist[i][1] == 1 else 0 for i in range(len(mnist))]\n",
        "mask = torch.tensor(mask)\n",
        "sampler = YourSampler(mask, mnist)\n",
        "new_data = torch.utils.data.DataLoader(mnist,sampler = sampler, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "gt2Vi6WMUTPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the dtype of the images in the first batch\n",
        "for images, labels in new_data:\n",
        "    print(\"Images dtype:\", images.dtype)  # Print dtype of the images\n",
        "    break  # Stop after the first batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8MJ7v5FRjxR",
        "outputId": "d3dd7e46-6e24-4181-ea02-8588c04c84cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images dtype: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "# Iterate through the DataLoader and collect all batches\n",
        "for images, labels in new_data:\n",
        "    all_images.append(images)\n",
        "    all_labels.append(labels)\n",
        "\n",
        "# Concatenate the list of tensors to form a single tensor\n",
        "all_images = torch.cat(all_images)\n",
        "all_labels = torch.cat(all_labels)\n",
        "\n",
        "\n",
        "all_images.data.shape  # output is #torch.Size([12700, 1, 28, 28])  [# of images, # of color channels, height of the image, width of the image]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wji16ggKSiF0",
        "outputId": "371e8378-3148-4147-87d9-ae31c0ec1a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12665, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trying the split test**"
      ],
      "metadata": {
        "id": "YU7V0m4uOs58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first convert the extracted new_data into pandas df"
      ],
      "metadata": {
        "id": "y6IhK8euWtgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_list = []\n",
        "for batch_data, batch_labels in new_data:\n",
        "    # batch_data = batch_data.numpy()\n",
        "    batch_data = batch_data.view(batch_data.size(0), -1).numpy()  # Flatten images\n",
        "    batch_labels = batch_labels.numpy()\n",
        "    data_list.extend(zip(batch_data, batch_labels))\n",
        "\n",
        "full_data = pd.DataFrame(data_list, columns=['x', 'y'])\n",
        "print(full_data)\n",
        "\n",
        "print(full_data.dtypes)  # Check the data types of the DataFrame columns\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gKXOTDDP6oW",
        "outputId": "3b0cf828-3124-43bf-ca3b-2751254d2435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                       x  y\n",
            "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0\n",
            "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1\n",
            "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1\n",
            "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1\n",
            "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1\n",
            "...                                                  ... ..\n",
            "12660  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0\n",
            "12661  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1\n",
            "12662  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1\n",
            "12663  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0\n",
            "12664  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1\n",
            "\n",
            "[12665 rows x 2 columns]\n",
            "x    object\n",
            "y     int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(full_data['y'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02yhl3EiQYFu",
        "outputId": "eda9c08f-8b3a-4d82-df35-d4a9ae5c4857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        0\n",
            "1        1\n",
            "2        1\n",
            "3        1\n",
            "4        1\n",
            "        ..\n",
            "12660    0\n",
            "12661    1\n",
            "12662    1\n",
            "12663    0\n",
            "12664    1\n",
            "Name: y, Length: 12665, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = full_data.sort_values('y').reset_index(drop=True)\n",
        "data.head()\n",
        "\n",
        "data['y'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "PuE9WyJaWnXz",
        "outputId": "0f525fb5-7993-40b7-eb40-c39d2d55186a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "y\n",
              "1    6742\n",
              "0    5923\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now perform the test split for to get unbalanced batch proportions"
      ],
      "metadata": {
        "id": "sQZVRbBwRr-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "p = 0.7 # The proportion of class 0 instances for all even batches\n",
        "q = 0.9 # The proportion of class 0 instances for all odd batches\n",
        "\n",
        "\n",
        "batch_index = 0\n",
        "\n",
        "full_data['Batch'] = -1\n",
        "\n",
        "while(True):\n",
        "    prop = p if (batch_index % 2 == 0) else q\n",
        "    num_class_a_elts = int(batch_size * prop)\n",
        "    num_class_b_elts = batch_size - num_class_a_elts\n",
        "\n",
        "    class_a_unassigned = full_data[(full_data['y'] == 0) & (full_data['Batch'] == -1)]\n",
        "    class_b_unassigned = full_data[(full_data['y'] == 1) & (full_data['Batch'] == -1)]\n",
        "\n",
        "    if class_a_unassigned.shape[0] < num_class_a_elts or \\\n",
        "        class_b_unassigned.shape[0] < num_class_b_elts:\n",
        "        print(\"Total number of batches:\", batch_index)\n",
        "        break\n",
        "    else:\n",
        "        full_data.loc[class_a_unassigned.sample(num_class_a_elts).index, 'Batch'] = batch_index\n",
        "        full_data.loc[class_b_unassigned.sample(num_class_b_elts).index, 'Batch'] = batch_index\n",
        "        batch_index += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDvgZ4vzOsba",
        "outputId": "db39b209-f415-4cbd-94c3-355b76bf2779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of batches: 740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "test_size = 0.2\n",
        "full_data = full_data[full_data['Batch'] != -1]  # remove the rows with -1 in the batch column from full_data\n",
        "\n",
        "num_batches = full_data['Batch'].nunique()\n",
        "print(\"Number of batches:\", num_batches)\n",
        "\n",
        "num_test_batches = int(num_batches * test_size)\n",
        "num_train_batches = num_batches - num_test_batches\n",
        "\n",
        "training_data = full_data[full_data['Batch'] < num_train_batches]\n",
        "test_data = full_data[full_data['Batch'] >= num_train_batches]\n",
        "\n",
        "num_batches = training_data['Batch'].nunique()\n",
        "print(\"Number of training batches:\", num_batches)\n",
        "\n",
        "num_t_batches = test_data['Batch'].nunique()\n",
        "print(\"Number of testing batches:\", num_t_batches)\n",
        "\n",
        "input_col = ['x']\n",
        "#training_data.to_excel(\"traindata.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXwgTHyQXU8o",
        "outputId": "ba2ab0a8-d5c5-4795-f0e5-51cf36e93453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches: 740\n",
            "Number of training batches: 592\n",
            "Number of testing batches: 148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_batches = training_data.groupby('Batch')  # group training data by batch\n",
        "\n",
        "# images in the same batch will have the same number in the batch column\n",
        "\n",
        "# Show the first batch in training data\n",
        "for num, batch in training_data_batches:\n",
        "    print(\"Batch:\", num)\n",
        "    print(batch)\n",
        "    break"
      ],
      "metadata": {
        "id": "kc3-JP5PZG6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35306918-48e1-47be-c204-2226ff732b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0\n",
            "                                                       x  y  Batch\n",
            "700    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0      0\n",
            "751    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0      0\n",
            "5579   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0      0\n",
            "6656   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0      0\n",
            "6709   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1      0\n",
            "7418   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0      0\n",
            "7507   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1      0\n",
            "9528   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0      0\n",
            "11582  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1      0\n",
            "12384  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "define the batch statistics function"
      ],
      "metadata": {
        "id": "aezeQ2mh8Eij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_stats(data):\n",
        "    batch_proportions = []\n",
        "    batch_weights = []\n",
        "\n",
        "    # Group data by 'Batch'\n",
        "    for batch, group in data.groupby('Batch'):\n",
        "        # Count occurrences of 0s and 1s in the 'y' column\n",
        "        numofzerosinbatch = (group['y'] == 0).sum()\n",
        "        numofonesinbatch = (group['y'] == 1).sum()\n",
        "        totalinbatch = numofzerosinbatch + numofonesinbatch\n",
        "\n",
        "        # Calculate percentages (proportions)\n",
        "        if totalinbatch > 0:\n",
        "            zerostats = (numofzerosinbatch / totalinbatch) * 100\n",
        "            onestats = (numofonesinbatch / totalinbatch) * 100\n",
        "        else:\n",
        "            zerostats = onestats = 0.0  # Handle cases where there is no data in the batch\n",
        "\n",
        "        # Calculate weights based on the proportions in the batch\n",
        "        if numofzerosinbatch > 0 and numofonesinbatch > 0:\n",
        "            weight_for_class_0 = totalinbatch / (2 * numofzerosinbatch)\n",
        "            weight_for_class_1 = totalinbatch / (2 * numofonesinbatch)\n",
        "        else:\n",
        "            weight_for_class_0 = weight_for_class_1 = 1.0  # Handle cases with only one class in the batch\n",
        "\n",
        "        # Store the proportions and weights for the batch\n",
        "        batch_proportions.append([zerostats, onestats])\n",
        "        batch_weights.append([weight_for_class_0, weight_for_class_1])\n",
        "\n",
        "    return batch_proportions, batch_weights\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5-rz4QkbUTRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "My neural network class"
      ],
      "metadata": {
        "id": "NYolzVBuSLoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NeuralNet Class\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, n_features: int, n_hidden: int, n_new_classes: int) -> None:\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.h1 = nn.Linear(n_features, n_hidden)  # 784 input features to 100 hidden neurons\n",
        "        self.out = nn.Linear(n_hidden, n_new_classes)   # 100 neurons to 2 output classes (not 10)\n",
        "\n",
        "    def forward(self, x):  # weights and biases\n",
        "        out = torch.relu(self.h1(x))\n",
        "        out = self.out(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "fkJ3q4SLTSWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define a custom loss"
      ],
      "metadata": {
        "id": "-43azhOR9f1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LossFunction(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LossFunction, self).__init__()\n",
        "\n",
        "    def forward(self, predictions, mean_l):\n",
        "        mean_p = torch.mean(predictions)   #take the mean of the models predictions for a single batch\n",
        "        mean_l = torch.tensor(mean_l, dtype=torch.float32)  # compare it with the target mean value\n",
        "\n",
        "        return torch.square(mean_p - mean_l)    # return the squared error"
      ],
      "metadata": {
        "id": "Evia-0wP9e2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "model = NeuralNetwork(n_features, n_hidden, n_new_classes).to(device)   #initialize my model\n",
        "\n",
        "# Loss and optimizer\n",
        "loss_fn = LossFunction()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "MkaV2h7XTq7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = torch.tensor(test_data['x'].tolist(), dtype=torch.float32)\n",
        "\n",
        "input_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCwAhTfmA9Xs",
        "outputId": "67169450-da13-410f-b209-d876dc2fb55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-f5486a4a1ad0>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  input_data = torch.tensor(test_data['x'].tolist(), dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check where the error (multilabel-indicator targets) is coming from\n",
        "\n",
        "- My predictions tensor has a shape of (n, 2)\n",
        "- For each image, the model outputs raw logits for each class [logit score for class 0, logit score for class 1]\n",
        "- It needs to have the shape (n,1), one value for each image so it can be compared properly with the actual target labels\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lHtupXomSSK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(input_data).detach().numpy()\n",
        "predictions = np.where(predictions < 0.5, 1, 0)   # 1 for values < 0.5 and 0 for values >= 0.5\n",
        "predictions = predictions[:, 0] # retrieve the first column, the probabilities for class 0\n",
        "\n",
        "predictions[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1ahg-qgxdoA",
        "outputId": "237580de-1300-4373-b10f-17fe6a8eb18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_0_data = test_data[test_data['y'] == 1]\n",
        "input_data_class_0 = torch.tensor(class_0_data['x'].tolist(), dtype=torch.float32)\n",
        "predictions_class_0 = model(input_data_class_0).detach().numpy()\n",
        "mu = np.mean(predictions_class_0)\n",
        "\n",
        "mu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbjclp72T6lE",
        "outputId": "edd75f2a-44f1-4e52-945d-1f43fb2ffbf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.102287784"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = test_data['y']\n",
        "targets[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "K1Da8j1JO7jG",
        "outputId": "1e7589a0-c591-4a85-a0d8-786662d2f0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12    0\n",
              "13    1\n",
              "17    0\n",
              "22    1\n",
              "35    0\n",
              "Name: y, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "\n",
        "    model.train()\n",
        "    loss_epoch = []\n",
        "\n",
        "    for num, batch in training_data_batches:\n",
        "\n",
        "        prop = batch['y'].value_counts()[0] / batch.shape[0]    #calculates the proportions of the most frequent value in the batch\n",
        "\n",
        "        # Create a tensor from the images in the batch\n",
        "        model_input = torch.tensor(batch['x'].tolist(), dtype=torch.float32)\n",
        "\n",
        "\n",
        "        output = model(model_input)  # Assuming the output is in the shape of batch size\n",
        "\n",
        "        # Calculate loss using the custom loss function\n",
        "        loss = loss_fn(output, prop)\n",
        "\n",
        "        # Backpropagation and optimizer step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Track loss for the epoch\n",
        "        loss_epoch.append(loss.detach().numpy())\n",
        "\n",
        "    input_data = torch.tensor(test_data['x'].tolist(), dtype=torch.float32)\n",
        "  # input_data = torch.tensor(test_data[input_col].values, dtype=torch.float32)\n",
        "\n",
        "    # Get model predictions\n",
        "    predictions = model(input_data).detach().numpy()\n",
        "    predictions = np.where(predictions < 0.5, 1, 0)   # 1 for probablilty < 0.5 and 0 for probability >= 0.5\n",
        "    predictions = predictions[:, 0]  # retrieve the first row\n",
        "    # maybe apply softmax for more classes get the more likely class\n",
        "\n",
        "    targets = test_data['y']\n",
        "    test_acc = accuracy_score(targets, predictions)  # Accuracy = Total Number of Predictions / Number of Correct Predictions\n",
        "\n",
        "\n",
        "\n",
        "    # Examine this\n",
        "    # Calculate mu: The average error for a class 1 instance\n",
        "    class_0_data = test_data[test_data['y'] == 1]\n",
        "    input_data_class_0 = torch.tensor(class_0_data['x'].tolist(), dtype=torch.float32)\n",
        "    predictions_class_0 = model(input_data_class_0).detach().numpy()\n",
        "    mu = np.mean(predictions_class_0)\n",
        "\n",
        "    # Calculate nu: The average error for a class 0 instance\n",
        "    class_1_data = test_data[test_data['y'] == 0]\n",
        "    input_data_class_1 = torch.tensor(class_1_data['x'].tolist(), dtype=torch.float32)\n",
        "    predictions_class_1 = model(input_data_class_1).detach().numpy()\n",
        "    nu = np.mean(1 - predictions_class_1)\n",
        "\n",
        "    # accuracy of mu and nu?\n",
        "\n",
        "    return loss_epoch, test_acc, mu, nu\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ENF6qQkxyaCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history = []\n",
        "test_history = []\n",
        "mu_history = []\n",
        "nu_history = []\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss_epoch, test_acc, mu, nu = train(epoch)\n",
        "    print(\"Epoch:\", epoch, \"Loss:\", np.mean(loss_epoch), \"Test Accuracy:\", test_acc, \"mu, nu:\", mu, nu)\n",
        "    loss_history.append(loss_epoch)\n",
        "    test_history.append(test_acc)\n",
        "    mu_history.append(mu)\n",
        "    nu_history.append(nu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mDtN_CTxvKP",
        "outputId": "f3518255-81f5-4f82-be52-a5b6682a3efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Loss: 0.016057061 Test Accuracy: 0.9898648648648649 mu, nu: 0.15643258 0.081655376\n",
            "Epoch: 2 Loss: 0.0038652308 Test Accuracy: 0.9912162162162163 mu, nu: 0.06065909 0.05175636\n",
            "Epoch: 3 Loss: 0.0034738062 Test Accuracy: 0.9925675675675676 mu, nu: 0.044213854 0.04188663\n",
            "Epoch: 4 Loss: 0.0031710896 Test Accuracy: 0.9932432432432432 mu, nu: 0.041161552 0.035543103\n",
            "Epoch: 5 Loss: 0.0028468973 Test Accuracy: 0.9939189189189189 mu, nu: 0.040104523 0.030767724\n",
            "Epoch: 6 Loss: 0.0025236995 Test Accuracy: 0.9939189189189189 mu, nu: 0.041266307 0.027371936\n",
            "Epoch: 7 Loss: 0.0022148436 Test Accuracy: 0.9939189189189189 mu, nu: 0.04289672 0.024836455\n",
            "Epoch: 8 Loss: 0.0019164982 Test Accuracy: 0.995945945945946 mu, nu: 0.04303621 0.021644443\n",
            "Epoch: 9 Loss: 0.0016496099 Test Accuracy: 0.9966216216216216 mu, nu: 0.04328472 0.01946662\n",
            "Epoch: 10 Loss: 0.001426054 Test Accuracy: 0.9979729729729729 mu, nu: 0.043185174 0.017955247\n",
            "Epoch: 11 Loss: 0.0012394551 Test Accuracy: 0.9979729729729729 mu, nu: 0.043301143 0.019120097\n",
            "Epoch: 12 Loss: 0.0010822943 Test Accuracy: 0.9986486486486487 mu, nu: 0.04271561 0.019154197\n",
            "Epoch: 13 Loss: 0.0009556306 Test Accuracy: 0.9986486486486487 mu, nu: 0.041847337 0.021677509\n",
            "Epoch: 14 Loss: 0.00084466196 Test Accuracy: 0.9986486486486487 mu, nu: 0.041440047 0.022806477\n",
            "Epoch: 15 Loss: 0.00075278344 Test Accuracy: 0.9986486486486487 mu, nu: 0.04134506 0.022004275\n",
            "Epoch: 16 Loss: 0.0006761254 Test Accuracy: 0.9986486486486487 mu, nu: 0.04196931 0.022369122\n",
            "Epoch: 17 Loss: 0.00060525874 Test Accuracy: 0.9986486486486487 mu, nu: 0.04243174 0.021801263\n",
            "Epoch: 18 Loss: 0.0005475014 Test Accuracy: 0.9986486486486487 mu, nu: 0.04215964 0.019390386\n",
            "Epoch: 19 Loss: 0.0004882456 Test Accuracy: 0.9986486486486487 mu, nu: 0.042985424 0.016953772\n",
            "Epoch: 20 Loss: 0.00044006744 Test Accuracy: 0.9986486486486487 mu, nu: 0.04283536 0.01590693\n",
            "Epoch: 21 Loss: 0.0003978288 Test Accuracy: 0.9986486486486487 mu, nu: 0.044160776 0.014625624\n",
            "Epoch: 22 Loss: 0.00035631898 Test Accuracy: 0.9986486486486487 mu, nu: 0.045091245 0.012556962\n",
            "Epoch: 23 Loss: 0.00031841244 Test Accuracy: 0.9986486486486487 mu, nu: 0.047303334 0.010529441\n",
            "Epoch: 24 Loss: 0.0002830539 Test Accuracy: 0.9986486486486487 mu, nu: 0.049003594 0.009498083\n",
            "Epoch: 25 Loss: 0.0002545256 Test Accuracy: 0.9986486486486487 mu, nu: 0.051468253 0.010177649\n",
            "Epoch: 26 Loss: 0.00022869225 Test Accuracy: 0.9986486486486487 mu, nu: 0.05204236 0.008320425\n",
            "Epoch: 27 Loss: 0.0002022714 Test Accuracy: 0.9986486486486487 mu, nu: 0.052399572 0.008003067\n",
            "Epoch: 28 Loss: 0.00018259556 Test Accuracy: 0.9986486486486487 mu, nu: 0.052257143 0.0062453607\n",
            "Epoch: 29 Loss: 0.00016680246 Test Accuracy: 0.9986486486486487 mu, nu: 0.05317302 0.0056146313\n",
            "Epoch: 30 Loss: 0.00015746128 Test Accuracy: 0.9986486486486487 mu, nu: 0.05268865 0.006890971\n",
            "Epoch: 31 Loss: 0.000150694 Test Accuracy: 0.9986486486486487 mu, nu: 0.054224774 0.007884737\n",
            "Epoch: 32 Loss: 0.0001543307 Test Accuracy: 0.9986486486486487 mu, nu: 0.056397878 0.008900943\n",
            "Epoch: 33 Loss: 0.00017008468 Test Accuracy: 0.9986486486486487 mu, nu: 0.057079624 0.009026848\n",
            "Epoch: 34 Loss: 0.0002388312 Test Accuracy: 0.9986486486486487 mu, nu: 0.05480303 0.010751041\n",
            "Epoch: 35 Loss: 0.0004507878 Test Accuracy: 0.9986486486486487 mu, nu: 0.03869211 0.045541234\n",
            "Epoch: 36 Loss: 0.00058555923 Test Accuracy: 0.9979729729729729 mu, nu: 0.02921931 0.055905245\n",
            "Epoch: 37 Loss: 0.0005314123 Test Accuracy: 0.9979729729729729 mu, nu: 0.035398096 0.030702561\n",
            "Epoch: 38 Loss: 0.00048404187 Test Accuracy: 0.9972972972972973 mu, nu: 0.042993423 0.012295902\n",
            "Epoch: 39 Loss: 0.00046440103 Test Accuracy: 0.9979729729729729 mu, nu: 0.048618216 -0.0007323983\n",
            "Epoch: 40 Loss: 0.00045599556 Test Accuracy: 0.9979729729729729 mu, nu: 0.05161175 -0.008346392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wYCiwPYA8tkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4aQUcnXv8tsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6UOTTPB48tzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing with a dataloader"
      ],
      "metadata": {
        "id": "ESMCrL5quC7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset   # TensorDataset allows for the creation of a dataset from tensors\n",
        "\n",
        "# Convert the 'x' and 'y' columns to tensors\n",
        "# Assuming 'x' is already flattened as a NumPy array and 'y' contains labels\n",
        "test_images = torch.tensor(test_data['x'].tolist(), dtype=torch.float32)  # Convert both to tensors\n",
        "test_labels = torch.tensor(test_data['y'].tolist(), dtype=torch.int)\n",
        "\n",
        "# Create a TensorDataset\n",
        "test_dataset = TensorDataset(test_images, test_labels)\n",
        "\n",
        "# Step 4: Create a DataLoader\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "FkJJ9GSNZlGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    n_samples = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28 * 28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "        n_samples += labels.shape[0]\n",
        "        n_correct += (predictions == labels).sum().item()\n",
        "\n",
        "    accuracy = n_correct / n_samples\n",
        "    print(f\"Accuracy is: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvCLO7EqeTGG",
        "outputId": "73763e36-108e-4c23-e1ad-c20039b037f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is: 0.7972972972972973\n"
          ]
        }
      ]
    }
  ]
}